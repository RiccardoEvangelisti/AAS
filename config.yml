# Graphics
RENDER:
    mode: "human"
    wait_timestep_ms: 700

# Grid
n_squares_width: 7
n_squares_height: 6

############################################
# Training
num_episodes: 3000
saving_freq: 500
train_code: &train_code "L"

############################################
# Random
Random: &Random
    name: "Random"
    EPSILON: 1
    EPSILON_rateDecay: 1
    pickle_filename: ""

# RuleBased 
RuleBased: &RuleBased
    name: "RuleBased"
    EPSILON: 0
    EPSILON_rateDecay: 1 #"half_linear_over_episodes" #"linear_over_episodes"
    pickle_filename: ""

# Q_learning parameters
Q_Learning: &Q_Learning
    name: "Q_Learning"
    EPSILON: 0 
    EPSILON_rateDecay: 1 #"linear_over_episodes" # Exploration rate decay
    ALPHA: 0.1 # Learning rate
    GAMMA: 0.9 # Discount factor
    pickle_filename: "outputs/q_learning_values"
    train_code: *train_code

# DQN parameters
DQN: &DQN
    name: "DQN"
    minibatch_size: 512 # Number of experiences to sample from memory
    replay_buffer_size: 50000
    target_update_freq: 1000
    EPSILON: 0
    EPSILON_rateDecay: 1 #"linear_over_episodes"
    ALPHA: 0.1 # Learning rate
    GAMMA: 0.9 # Discount factor
    pickle_filename: "outputs/dqn_values"
    train_code: *train_code

############################################
# Agents
player:
    max_hp: 50
    movement_speed: 5
    attack_damage: 10
    attacks_max_number: 1
    picture_path: "pictures/Erik combat pose-token.png"
    name: "Erik"
    default_coordinates: "random"
    algorithm: *Q_Learning # NEEDS to be an alias of the algorithm (the "*")

monster:
    max_hp: 100
    movement_speed: 2
    attack_damage: 10
    attacks_max_number: 2
    picture_path: "pictures/mimic2-token.png"
    name: "Mimic"
    default_coordinates: "random"
    algorithm: *RuleBased # NEEDS to be an alias of the algorithm (the "*")

# Reward System
advanced_reward: False

############################################

# Experiment B
# statistics_filename: "statistics/DQN_B"
# + DQN, AdvancedReward, Erik linear epsilon decay over all episodes, alpha=0.1, Mimic FullMovement FullAttacks, Mimic RuleBased Strategy with epsilon half-linear decay, 1k episodes, Mimic speed=2, 64 nodes

# Experiment C
# statistics_filename: "statistics/DQN_C"
# + DQN, SimpleReward, Erik half-linear epsilon decay over all episodes, alpha=0.2, Mimic FullMovement FullAttacks, Mimic RuleBased Strategy with epsilon half-linear decay, 10k episodes, Mimic speed=2, 64 nodes

# Experiment D
# statistics_filename: "statistics/DQN_D"
# + DQN, SimpleReward, Erik linear epsilon decay over all episodes, alpha=0.1, Mimic FullMovement FullAttacks, Mimic RuleBased Strategy with epsilon half-linear decay, 3k episodes, Mimic speed=2, 128 nodes


statistics_filename: "statistics/QL_L"